{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a47ae972",
   "metadata": {},
   "source": [
    "Emotion detection deep learning model from images using Transfer Learning\n",
    "---\n",
    "\n",
    "---\n",
    "\n",
    "link: https://www.kaggle.com/code/odins0n/emotion-detection\n",
    "\n",
    "dataset: https://www.kaggle.com/datasets/ananthu017/emotion-detection-fer\n",
    "\n",
    "DL model simulator: https://playground.tensorflow.org/#activation=tanh&batchSize=10&dataset=circle&regDataset=reg-plane&learningRate=0.03&regularizationRate=0&noise=0&networkShape=4,2&seed=0.92535&showTestData=false&discretize=false&percTrainData=50&x=true&y=true&xTimesY=false&xSquared=false&ySquared=false&cosX=false&sinX=false&cosY=false&sinY=false&collectStats=false&problem=classification&initZero=false&hideText=false\n",
    "\n",
    "---\n",
    "\n",
    "This code implements and train a deep learning model capable of analyzing a given image and recognize the emotion the person is expressing to then return the corresponding emoji that mirrors said emotion. For this particular implementation transfer learning is included for higher accuracy\n",
    "\n",
    "---\n",
    "Machine Learning\n",
    "\n",
    "By: Sebastian Russo\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90de9da2",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d52b2e10",
   "metadata": {},
   "source": [
    "Imports\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e83f36f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Necessary libraries\n",
    "#Logging\n",
    "import logging\n",
    "import os\n",
    "import sys\n",
    "\n",
    "#Dataset analysis\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt   \n",
    "%matplotlib inline\n",
    "import seaborn as sns \n",
    "import plotly.express as pxt \n",
    "\n",
    "#Pre-Pre-processing image visualization\n",
    "from PIL import Image             \n",
    "\n",
    "#Deep Learning model itself\n",
    "import tensorflow as tf           #Open source library for AI, ML and DL\n",
    "from tensorflow import keras      #Integrated tensorflow API to implement high-level neural networks\n",
    "from itertools import cycle       #Import cycle function from itertools\n",
    "\n",
    "#Performance metrics to analyze model's performance\n",
    "from sklearn.metrics import accuracy_score,f1_score,precision_score,recall_score,classification_report,confusion_matrix\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score, precision_recall_curve,average_precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0de5d101",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up log file path\n",
    "log_file_path = \"../log_history.log\"\n",
    "\n",
    "# Clear existing handlers if any (to avoid duplication or misconfiguration)\n",
    "for handler in logging.root.handlers[:]:\n",
    "    logging.root.removeHandler(handler)\n",
    "\n",
    "# Configure logging explicitly\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s | %(levelname)s | %(message)s |\",\n",
    "    handlers=[\n",
    "        logging.FileHandler(log_file_path, mode=\"a\"),  # Append mode\n",
    "        logging.StreamHandler(sys.stdout)  # Print to console\n",
    "    ]\n",
    ")\n",
    "\n",
    "logging.info(\"Logging is set up. All logs of transfer learning model will be saved to log_history.log in the root directory.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96ff321e",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eb4271d",
   "metadata": {},
   "source": [
    "Hyper-parameters and global variables\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecd46094",
   "metadata": {},
   "outputs": [],
   "source": [
    "#General variables\n",
    "#Directory paths from extracted zip (train data and test data)\n",
    "train_directory = \"../dataset/train\"\n",
    "test_directory = \"../dataset/test\"\n",
    "model_name = \"emotion_detection_from_image_transfer_learning.h5\" #Either save in .h5 or native .keras\n",
    "\n",
    "#Fixed images measurements\n",
    "img_height = 48\n",
    "img_width = 48\n",
    "\n",
    "#Number of samples to be processed before the model is updated\n",
    "batch_size = 64\n",
    "\n",
    "#Fixed seed value for random number generators to ensure reproducibility\n",
    "fixed_seed = 12\n",
    "\n",
    "#Number of complete passes through the training dataset (may change)\n",
    "epochs = 30 #Recommended \n",
    "#Number of epochs to run for fine-tuning after initial training\n",
    "fine_tuning_epochs = 20 #Recommended\n",
    "\n",
    "#Hyperparameter to control the change in the model based on estimated error each time model weights change\n",
    "learn_r = 0.01\n",
    "#Number of epochs with no improvements before model is forced to stop\n",
    "early_stop_crit=3\n",
    "\n",
    "#Image related variables\n",
    "#7 classes for seven emotions and of course 2 arrays with the lables and actual emojis\n",
    "class_labels  = ['Anger', 'Disgust', 'Fear', 'Happy', 'Neutral', 'Sadness', 'Surprise']\n",
    "class_label_emojis = [\"üëø\", \"ü§¢\" , \"üò±\" , \"üòä\" , \"üòê \", \"üòî\" , \"üò≤\" ]\n",
    "class_nums = len(class_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6346763b",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae21f1d6",
   "metadata": {},
   "source": [
    "Data pre-processing\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a06ada9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#To preprocesses input image data so it is suitable for DenseNet\n",
    "#neural models (scale and normalize pixels)\n",
    "pre_process_method = tf.keras.applications.densenet.preprocess_input #better for large datasets\n",
    "\n",
    "#--------------------------------------------------------------------------------------------------------\n",
    "#Image data generator to augment and preprocess each data point (image) for training\n",
    "#It actually transforms given .png\n",
    "train_data = keras.preprocessing.image.ImageDataGenerator (\n",
    "    horizontal_flip=True,     #Randomly flips the images horizontally\n",
    "\n",
    "    width_shift_range=0.1,    #Shift image 10% of its horizontally at random\n",
    "    height_shift_range=0.05,  #Shift image 5% of its vertically at random\n",
    "    rescale = 1./255,         #Rescale pixels to range [0,1] and divide it in 255 pieces\n",
    "\n",
    "    validation_split = 0.2,   #Split data 80-20% training-validation\n",
    "\n",
    "    preprocessing_function=pre_process_method #Use preprocess function for DenseNet, now pixels are [-1,1]\n",
    ")\n",
    "\n",
    "#Image data generator to preprocess each data point (image) for testing\n",
    "#It actually transforms given .png\n",
    "test_data = keras.preprocessing.image.ImageDataGenerator(\n",
    "    rescale = 1./255,           #Rescale pixels to range [0,1] and divide it in 255 pieces\n",
    "\n",
    "    validation_split = 0.2,     #Split data 80-20% training-testing\n",
    "\n",
    "    preprocessing_function=pre_process_method #Use preprocess function for DenseNet, now pixels are [-1,1]\n",
    ")\n",
    "\n",
    "#--------------------------------------------------------------------------------------------------------\n",
    "#Train data generator to load and preprocess image, applies preprocess, yield batches of images and their labels for training\n",
    "#Xtrain (images) and Ytrain (their labels)\n",
    "train_generator = train_data.flow_from_directory(#Go through each file in the specified directory\n",
    "    directory = train_directory,             #Specified directory, /content/train\n",
    "\n",
    "    target_size = (img_height,img_width),     #Specify measurements of images\n",
    "    batch_size = batch_size,                 #Provide number of images per batch (64)\n",
    "    shuffle  = True,                        #Modify the order of the data points\n",
    "    color_mode = \"rgb\",                     #Load images in RGB format\n",
    "\n",
    "    class_mode = \"categorical\",             #Since we have 7 classes, specify as categorical (one-hot encode)\n",
    "\n",
    "    subset = \"training\",                    #Specify as training subset (80%)\n",
    "    seed = fixed_seed                        #Use fixed seed for random operations, shuffle and split (12)\n",
    ")\n",
    "\n",
    "#Train data generator to load and preprocess image applies preprocess, yield batches of imags and their labels for validation\n",
    "#Xvalidation (images) and Yvalidation (their labels)\n",
    "train_validation_generator = train_data.flow_from_directory(\n",
    "    directory = train_directory,           #Specified directory, /content/train\n",
    "\n",
    "    target_size = (img_height ,img_width),  #Specify measurements of images\n",
    "    batch_size = batch_size,               #Provide number of images per batch (64)\n",
    "    shuffle  = True,                      #Modify the order of the data points\n",
    "    color_mode = \"rgb\",                   #Load images in RGB format\n",
    "\n",
    "    class_mode = \"categorical\",           #Since we have 7 classes, specify as categorical (one-hot encode)\n",
    "\n",
    "    subset = 'validation',                #Specify as training subset (20%)\n",
    "    seed = fixed_seed                      #Use fixed seed for random operations, shuffle and split (12)\n",
    ")\n",
    "\n",
    "#Test data generator to load and preprocess image applies preprocess, yield batches of imags and their labels for testing\n",
    "#Xtest (images) and Ytest (their labels)\n",
    "test_generator = test_data.flow_from_directory(\n",
    "    directory = test_directory,            #Specified directory, /content/test\n",
    "\n",
    "    target_size = (img_height,img_width),  #Specify measurements of images\n",
    "    batch_size = batch_size,               #Provide number of images per batch (64)\n",
    "    shuffle  = False,                     #Don't modify the order of the data points, keep it constant\n",
    "    color_mode = \"rgb\",                   #Load images in RGB format\n",
    "\n",
    "    class_mode = \"categorical\",           #Since we have 7 classes, specify as categorical (one-hot encode)\n",
    "    seed = fixed_seed                      #Use fixed seed for random operations, split (12)\n",
    ")\n",
    "\n",
    "#After this cell is executed, .png files will be converted into NumPy arrays in batches of 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c9ad547",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_generator, train_validation_generator and\n",
    "#test_generator are initialized data generators\n",
    "\n",
    "#Get the next batch of images and labels from the generator\n",
    "train_images, train_labels = next(train_generator)\n",
    "\n",
    "valid_images, valid_labels = next(train_validation_generator)\n",
    "\n",
    "test_images, test_labels = next(test_generator)\n",
    "\n",
    "#--------------------------------------------------------------------------------------------------------\n",
    "#Access a specific data point within the batch\n",
    "any_img = train_images[0]\n",
    "any_img_label = train_labels[0]\n",
    "\n",
    "any_valid_image = valid_images[0]\n",
    "any_valid_label = valid_labels[0]\n",
    "\n",
    "any_test_images = test_images[0]\n",
    "any_test_labels = test_labels[0]\n",
    "\n",
    "#--------------------------------------------------------------------------------------------------------\n",
    "#Log examples\n",
    "logging.info(\"Specific Image Shape:\", any_img.shape)\n",
    "logging.info(\"Specific Label:\", any_img_label)\n",
    "logging.info(\"Specific Image (numpy array):\",any_img)\n",
    "logging.info(\"\")\n",
    "\n",
    "logging.info(\"Validation Image Shape:\", any_valid_image.shape)\n",
    "logging.info(\"Validation Label:\", any_valid_label)\n",
    "logging.info(\"Validation Image (numpy array):\", any_valid_image)\n",
    "logging.info(\"\")\n",
    "\n",
    "logging.info(\"Test Image Shape:\", any_test_images.shape)\n",
    "logging.info(\"Test Label:\", any_test_labels)\n",
    "logging.info(\"Test Image (numpy array):\", any_test_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93a30a74",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0e123bf",
   "metadata": {},
   "source": [
    "DenseNet169 CNN architecture\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d5a4202",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Functions to implement the DenseNet DL model\n",
    "\n",
    "#To extract features from input (pre-processed) images using pre-trained convolutional\n",
    "#layers to capture hierarchical features of images\n",
    "def feature_extractor(inputs):\n",
    "\n",
    "    feature_extractor = tf.keras.applications.DenseNet169(\n",
    "                        input_shape=(img_height,img_width, 3),   #Specify the expected shape of inputs\n",
    "                        include_top=False,                     #Don't include fully connected layers\n",
    "                        weights=\"imagenet\")(inputs)            #Initialize model with pretrained weights\n",
    "\n",
    "    return feature_extractor\n",
    "\n",
    "#To take extracted features by DenseNet169 and perform final classification\n",
    "def DL_model_5_layers (inputs):\n",
    "    #1st layer, reduce parameters and prevent overfitting\n",
    "    DRE = tf.keras.layers.GlobalAveragePooling2D()(inputs)\n",
    "\n",
    "    #2nd layer: Dense layer with dropout for regularization\n",
    "    DRE = tf.keras.layers.Dense(\n",
    "        256,                                                      #number of neurons\n",
    "        activation=\"relu\",                                        #Rectified Linear Unit for hidden layers\n",
    "        kernel_regularizer = tf.keras.regularizers.l2(0.01))(DRE) #To penalize large weights and prevent overfitting\n",
    "    DRE = tf.keras.layers.Dropout(0.3)(DRE)  #Regularization technique to drop 30% of neurons at random\n",
    "\n",
    "    #3rd layer: Dense layer with dropout for regularization\n",
    "    DRE = tf.keras.layers.Dense(\n",
    "        1024,                                                     #number of neurons\n",
    "        activation=\"relu\",                                        #Rectified Linear Unit for hidden layers\n",
    "        kernel_regularizer = tf.keras.regularizers.l2(0.01))(DRE) #To penalize large weights and prevent overfitting\n",
    "    DRE = tf.keras.layers.Dropout(0.5)(DRE) #Regularization technique to drop 50% of neurons at random\n",
    "\n",
    "    #4th layer: Dense layer with dropout for regularization\n",
    "    DRE = tf.keras.layers.Dense(\n",
    "        512,                                                      #number of neurons\n",
    "        activation=\"relu\",                                        #Rectified Linear Unit for hidden layers\n",
    "        kernel_regularizer = tf.keras.regularizers.l2(0.01))(DRE) #To penalize large weights and prevent overfitting\n",
    "    DRE = tf.keras.layers.Dropout(0.5)(DRE) #Regularization technique to drop 50% of neurons at random\n",
    "\n",
    "    #5th layer, initialize dense (fully connected) layer in TensorFlow/Keras\n",
    "    DRE = tf.keras.layers.Dense(\n",
    "        7,                              #number of neurons equal to number of classes (7), One vs ALL\n",
    "        activation=\"softmax\",           #Use Softmax to scale each class into probabilities\n",
    "        name=\"classification\")(DRE)\n",
    "\n",
    "    return DRE\n",
    "\n",
    "#--------------------------------------------------------------------------------------------------------\n",
    "#Put together the feature extraction function and DL 5-layered model\n",
    "def final_DL_model(inputs):\n",
    "    dsnt_feat_extractor = feature_extractor(inputs)      #Extract features from input .pngs\n",
    "    classification_output = DL_model_5_layers(dsnt_feat_extractor) #Use extracted features as input to classify\n",
    "\n",
    "    return classification_output\n",
    "\n",
    "#Compile the model with specified optimizer, loss function, and metrics\n",
    "def dl_model_compiler():\n",
    "\n",
    "    inputs = tf.keras.layers.Input(     #Expected input shape\n",
    "        shape=(img_height ,img_width,3)\n",
    "    )\n",
    "\n",
    "    classification_output = final_DL_model(inputs) #Use the final model for Deep Learning\n",
    "    model = tf.keras.Model(\n",
    "        inputs=inputs,                   #Input layer\n",
    "        outputs = classification_output          #Output layer\n",
    "    )\n",
    "\n",
    "    model.compile(\n",
    "        #optimizer=\"adam\",                       #Optional optimizer\n",
    "        optimizer=tf.keras.optimizers.SGD(0.1),  #Selected optimizer\n",
    "        #loss=\"sparse_categorical_crossentropy\", #Optional loss function\n",
    "        loss='categorical_crossentropy',         #Selected loss function\n",
    "        metrics = ['accuracy']                    #selected metrics to evaluate\n",
    "    )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeaba9bb",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25e5a5a6",
   "metadata": {},
   "source": [
    "Train model with freezed layers, then unfreeze them\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d8f607a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_to_train overview\n",
    "model_to_train = dl_model_compiler()\n",
    "\n",
    "#Freezing the feature extraction layers\n",
    "model_to_train.layers[1].trainable = False\n",
    "\n",
    "model_to_train.summary()\n",
    "\n",
    "#Ensure data is correctly preprocessed to train model with freezed layers\n",
    "logging.info(f\"Training Generator: {train_generator.class_indices}\")\n",
    "logging.info(f\"Training Validation Generator: {train_validation_generator.class_indices}\")\n",
    "\n",
    "logging.info(f\"Batch size: {batch_size}\")\n",
    "\n",
    "images, labels = next(train_generator)\n",
    "logging.info(f\"Batch shape: {images.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49990227",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train model_to_train with freezed layers (Transfer learning)\n",
    "#Freeze the feature extraction layers, it is already frozen but just to be sure\n",
    "model_to_train.layers[1].trainable = False\n",
    "\n",
    "#Define Early Stopping callback to monitor validation loss (avoid overfitting)\n",
    "early_stop_callback = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',         #Monitor validation loss for early stopping\n",
    "    patience=early_stop_crit,   #Num of epochs with no improvement before stopping\n",
    "    verbose= 1,                 #Verbosity mode. 1 = progress bar line per epoch\n",
    "    restore_best_weights=True   #Restore model_to_train weights from the epoch\n",
    ")\n",
    "\n",
    "#Train the model_to_train with training generator and validate with validation generator\n",
    "history_1 = model_to_train.fit(\n",
    "    x = train_generator,                         #Training data generator\n",
    "    epochs = epochs,                             #Number of epochs to train the model_to_train\n",
    "    validation_data = train_validation_generator, #Validation data generator\n",
    "    callbacks= [early_stop_callback]              #List of callbacks to apply\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "591caf1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Un-Freeze the feature extraction layers for fine-tuning (Transfer learning)\n",
    "model_to_train.layers[1].trainable = True\n",
    "\n",
    "#Compile the model_to_train with different parameters\n",
    "model_to_train.compile(\n",
    "    optimizer=tf.keras.optimizers.SGD(0.001),  #Selected optimizer (lower LR)\n",
    "    loss='categorical_crossentropy',           #Selected loss function\n",
    "    metrics=['accuracy']                       #Selected metrics to evaluate\n",
    ")\n",
    "\n",
    "#Fine-tune model_to_train with training generator and validate with validation generator\n",
    "history_2 = model_to_train.fit(\n",
    "    x=train_generator,                          #Training data generator\n",
    "    epochs=fine_tuning_epochs,                   #Number of epochs for fine-tuning\n",
    "    validation_data=train_validation_generator   #Validation data generator\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57afd83a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert the history object into a DataFrame\n",
    "history_1_df = pd.DataFrame(history_1.history)\n",
    "\n",
    "#Convert the history of fine-tuning to a DataFrame\n",
    "history_2_df = pd.DataFrame(history_2.history)\n",
    "\n",
    "#Concatenate the history DataFrame with the new history DataFrame\n",
    "final_history = pd.concat([history_1_df, history_2_df], ignore_index=True)\n",
    "\n",
    "#Now we can evaluate the model's performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a2112e9",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b614ae9f",
   "metadata": {},
   "source": [
    "Model evaluation\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b502a751",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a line plot to visualize accuracy and validation accuracy over epochs\n",
    "model_plot = pxt.line(\n",
    "    data_frame=final_history,             #Use the history DataFrame for plotting\n",
    "    y=[\"accuracy\", \"val_accuracy\"],       #Plot both training and validation accuracy\n",
    "    markers=True                          #Show markers on the plot\n",
    ")\n",
    "\n",
    "#Update the x-axis title to indicate the number of epochs\n",
    "model_plot.update_xaxes(title=\"# of Epochs\")\n",
    "#Update the y-axis title to indicate the metric (Accuracy)\n",
    "model_plot.update_yaxes(title=\"Accuracy\")\n",
    "\n",
    "#Update the layout of the plot to show the legend, set the title, and adjust its position\n",
    "model_plot.update_layout(\n",
    "    showlegend=True,                            #Show the legend on the plot\n",
    "    title={\n",
    "        'text': 'Accuracy vs # of Epochs', #Title of the plot\n",
    "        'y': 0.94,                              #Vertical position of the title\n",
    "        'x': 0.5,                               #Horizontal position of the title\n",
    "        'xanchor': 'center',                    #Anchor point for horizontal position\n",
    "        'yanchor': 'top'                        #Anchor point for vertical position\n",
    "    }\n",
    ")\n",
    "\n",
    "#Display the plot\n",
    "model_plot.show()\n",
    "\n",
    "#--------------------------------------------------------------------------------------------------------\n",
    "#Create a line plot to visualize loss and validation loss over epochs\n",
    "model_plot = pxt.line(\n",
    "    data_frame=final_history,   #Use the history DataFrame for plotting\n",
    "    y=[\"loss\", \"val_loss\"],    #Plot both training and validation loss\n",
    "    markers=True               #Show markers on the plot\n",
    ")\n",
    "\n",
    "#Update the x-axis title to indicate the number of epochs\n",
    "model_plot.update_xaxes(title=\"# of Epochs\")\n",
    "#Update the y-axis title to indicate the metric (Loss)\n",
    "model_plot.update_yaxes(title=\"Loss\")\n",
    "\n",
    "#Update the layout of the plot to show the legend, set the title, and adjust its position\n",
    "model_plot.update_layout(\n",
    "    showlegend=True,                   #Show the legend on the plot\n",
    "    title={\n",
    "        'text': 'Loss vs # of Epochs',  #Title of the plot\n",
    "        'y': 0.94,                           #Vertical position of the title\n",
    "        'x': 0.5,                            #Horizontal position of the title\n",
    "        'xanchor': 'center',                 #Anchor point for horizontal position\n",
    "        'yanchor': 'top'                     #Anchor point for vertical position\n",
    "    }\n",
    ")\n",
    "\n",
    "#Display the plot\n",
    "model_plot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f498cff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluate the model_to_train on the test data generator\n",
    "model_to_train.evaluate(test_generator)\n",
    "\n",
    "#Make predictions on the test data generator\n",
    "predictions = model_to_train.predict(test_generator)\n",
    "\n",
    "#Extract the predicted labels by taking the index of the maximum probability in each prediction\n",
    "predict_Y = np.argmax(predictions, axis=1)\n",
    "\n",
    "#Extract the true labels from the test data generator\n",
    "Y_test = np.array(test_generator.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0598efa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compute the confusion matrix\n",
    "confusion_matrix_data = confusion_matrix(Y_test, predict_Y)\n",
    "\n",
    "#logging.info confusion matrix\n",
    "logging.info(\"Simple Confusion Matrix:\")\n",
    "logging.info(confusion_matrix_data)\n",
    "logging.info(\"\")\n",
    "\n",
    "#Create a pandas DataFrame for the confusion matrix with class labels as columns and indices\n",
    "logging.info(\"Heatmap Confusion Matrix:\")\n",
    "confusion_matrix = pd.DataFrame(\n",
    "    confusion_matrix_data,              #Confusion matrix data\n",
    "    columns=class_labels,      #Column labels uses class labels\n",
    "    index=class_labels         #Row labels uses class labels\n",
    ")\n",
    "\n",
    "#Set the index name for the true labels and column names for the predicted labels\n",
    "confusion_matrix.index.name = 'Actual'\n",
    "confusion_matrix.columns.name = 'Predicted'\n",
    "\n",
    "#Set the size of the figure for the heatmap\n",
    "plt.figure(figsize=(20, 10))\n",
    "\n",
    "#Set the title and font size for the confusion matrix plot\n",
    "plt.title('Confusion Matrix', fontsize=20)\n",
    "#Set the font scale for the heatmap\n",
    "sns.set(font_scale=1.2)\n",
    "\n",
    "#Create a heatmap using seaborn with the confusion matrix data\n",
    "model_heat = sns.heatmap(\n",
    "    confusion_matrix,                 #Matrix data to plot\n",
    "    cbar=True,               #Enable the color bar\n",
    "    cmap=\"inferno\",          #Blues colormap for the heatmap\n",
    "    annot=True,              #Annotate each cell with the numerical value\n",
    "    annot_kws={\"size\": 16},  #Set the text size\n",
    "    fmt='g'                  #Format test as general numbers (INT)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25dde923",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predict probabilities for the test data\n",
    "Y_predict_probabilities = model_to_train.predict(test_generator, verbose=1)\n",
    "\n",
    "#Convert the labels to one-hot encoding\n",
    "Y_test_one_hot_enc = tf.keras.utils.to_categorical(Y_test, num_classes=len(class_labels))\n",
    "\n",
    "#Initialize dictionaries to store fpr, tpr, and roc_auc for each class\n",
    "fpr = {}\n",
    "tpr = {}\n",
    "roc_auc = {}\n",
    "\n",
    "#Compute ROC metrics for each class\n",
    "for i in range(len(class_labels)):\n",
    "    fpr[i], tpr[i], _ = roc_curve(Y_test_one_hot_enc[:, i], Y_predict_probabilities[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "#Compute micro-average ROC curve and ROC area\n",
    "fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(Y_test_one_hot_enc.ravel(), Y_predict_probabilities.ravel())\n",
    "roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
    "\n",
    "#--------------------------------------------------------------------------------------------------------\n",
    "\n",
    "#Plot ROC curve for each class and micro-average\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.plot(fpr[\"micro\"], tpr[\"micro\"], label='Micro-average ROC curve (area = {0:0.2f})'\n",
    "        ''.format(roc_auc[\"micro\"]), color='deeppink', linestyle=':', linewidth=4)\n",
    "\n",
    "colors = cycle(['aqua', 'darkorange', 'cornflowerblue', 'green', 'red', 'purple', 'brown'])\n",
    "for i, color in zip(range(len(class_labels)), colors):\n",
    "    plt.plot(fpr[i], tpr[i], color=color, lw=2,\n",
    "            label='ROC curve of class {0} (area = {1:0.2f})'\n",
    "            ''.format(class_labels[i], roc_auc[i]))\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--', lw=2)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13003056",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize dictionaries to store precision, recall, and average precision\n",
    "precision = {}\n",
    "recall = {}\n",
    "average_precision = {}\n",
    "\n",
    "#Compute Precision-Recall metrics for each class\n",
    "for i in range(len(class_labels)):\n",
    "    precision[i], recall[i], _ = precision_recall_curve(Y_test_one_hot_enc[:, i], Y_predict_probabilities[:, i])\n",
    "    average_precision[i] = average_precision_score(Y_test_one_hot_enc[:, i], Y_predict_probabilities[:, i])\n",
    "\n",
    "#Compute micro-average Precision-Recall curve and PR area\n",
    "precision[\"micro\"], recall[\"micro\"], _ = precision_recall_curve(Y_test_one_hot_enc.ravel(), Y_predict_probabilities.ravel())\n",
    "average_precision[\"micro\"] = average_precision_score(Y_test_one_hot_enc, Y_predict_probabilities, average=\"micro\")\n",
    "\n",
    "#--------------------------------------------------------------------------------------------------------\n",
    "\n",
    "#Plot Precision-Recall curve for each class and micro-average\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.plot(recall[\"micro\"], precision[\"micro\"], color='gold', lw=2,\n",
    "        label='Micro-average Precision-recall curve (AP = {0:0.2f})'\n",
    "            ''.format(average_precision[\"micro\"]))\n",
    "\n",
    "colors = cycle(['aqua', 'darkorange', 'cornflowerblue', 'green', 'red', 'purple', 'brown'])\n",
    "for i, color in zip(range(len(class_labels)), colors):\n",
    "    plt.plot(recall[i], precision[i], color=color, lw=2,\n",
    "            label='Precision-recall curve of class {0} (AP = {1:0.2f})'\n",
    "            ''.format(class_labels[i], average_precision[i]))\n",
    "\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('Precision-Recall Curve')\n",
    "plt.legend(loc=\"lower left\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82e72028",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate and log the classification report\n",
    "logging.info(classification_report(Y_test, predict_Y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1333e890",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12cc1c1f",
   "metadata": {},
   "source": [
    "Save trained model\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a463bc3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# Create the directory using shell command, in case it does not exist\n",
    "directory_name = \"../trained_dl_models\"\n",
    "os.makedirs(directory_name, exist_ok=True)\n",
    "\n",
    "# Define the model path\n",
    "model_path = os.path.join(directory_name, model_name) \n",
    "# Save the model\n",
    "model_to_train.save(model_path)\n",
    "logging.info(f\"Model saved to {model_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
